PS D:\alex_ee4146> python -u ./train.py
Total # images:7876, labels:7876
Total # images:2624, labels:2624
D:\anaconda3\lib\site-packages\torch\optim\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()
` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
D:\anaconda3\lib\site-packages\torch\optim\lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. Du
ring the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch
/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

===> epoch: 1/20
train:
 493/493 [================================================================================>]  Step: 1s88ms | Tot: 36s883ms | Loss: 1.2006 | Acc: 55.510% (4372/7876)
(591.8972454071045, 0.5551041137633317)
test:
 164/164 [================================================================================>]  Step: 28ms | Tot: 4s938ms | Loss: 1.0157 | Acc: 67.721% (1777/2624)

===> epoch: 2/20
train:
 493/493 [================================================================================>]  Step: 42ms | Tot: 35s32ms | Loss: 0.7883 | Acc: 72.715% (5727/7876)
(388.6264479160309, 0.7271457592686643)
test:
 164/164 [================================================================================>]  Step: 26ms | Tot: 4s768ms | Loss: 0.7707 | Acc: 73.438% (1927/2624)

===> epoch: 3/20
train:
 493/493 [================================================================================>]  Step: 41ms | Tot: 34s980ms | Loss: 0.7151 | Acc: 75.089% (5914/7876)
(352.5209366083145, 0.7508887760284408)
test:
 164/164 [================================================================================>]  Step: 35ms | Tot: 4s739ms | Loss: 0.6005 | Acc: 80.259% (2106/2624)

===> epoch: 4/20
train:
 493/493 [================================================================================>]  Step: 41ms | Tot: 34s968ms | Loss: 0.6517 | Acc: 78.200% (6159/7876)
(321.3027146756649, 0.7819959370238699)
test:
 164/164 [================================================================================>]  Step: 31ms | Tot: 4s759ms | Loss: 0.5543 | Acc: 81.555% (2140/2624)

===> epoch: 5/20
train:
 493/493 [================================================================================>]  Step: 40ms | Tot: 34s879ms | Loss: 0.6747 | Acc: 77.501% (6104/7876)
(332.6285675764084, 0.7750126968004063)
test:
 164/164 [================================================================================>]  Step: 33ms | Tot: 4s794ms | Loss: 0.5365 | Acc: 81.250% (2132/2624)

===> epoch: 6/20
train:
 493/493 [================================================================================>]  Step: 42ms | Tot: 35s5ms | Loss: 0.5466 | Acc: 81.564% (6424/7876))
(269.46857196837664, 0.8156424581005587)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s703ms | Loss: 0.5535 | Acc: 81.479% (2138/2624)

===> epoch: 7/20
train:
 493/493 [================================================================================>]  Step: 41ms | Tot: 35s54ms | Loss: 0.5006 | Acc: 83.151% (6549/7876)
(246.7943791486323, 0.8315134586084306)
test:
 164/164 [================================================================================>]  Step: 33ms | Tot: 4s775ms | Loss: 0.4966 | Acc: 82.889% (2175/2624)

===> epoch: 8/20
train:
 493/493 [================================================================================>]  Step: 42ms | Tot: 35s52ms | Loss: 0.5278 | Acc: 81.907% (6451/7876)
(260.18991693109274, 0.819070594210259)
test:
 164/164 [================================================================================>]  Step: 29ms | Tot: 4s778ms | Loss: 0.4588 | Acc: 84.527% (2218/2624)

===> epoch: 9/20
train:
 493/493 [================================================================================>]  Step: 42ms | Tot: 34s990ms | Loss: 0.4729 | Acc: 84.015% (6617/7876)
(233.156418569386, 0.8401472828847131)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s766ms | Loss: 0.5242 | Acc: 83.460% (2190/2624)

===> epoch: 10/20
train:
 493/493 [================================================================================>]  Step: 41ms | Tot: 34s969ms | Loss: 0.4703 | Acc: 84.040% (6619/7876)
(231.86248445510864, 0.840401218892839)
test:
 164/164 [================================================================================>]  Step: 29ms | Tot: 4s757ms | Loss: 0.4391 | Acc: 85.633% (2247/2624)

===> epoch: 11/20
train:
 493/493 [================================================================================>]  Step: 42ms | Tot: 35s106ms | Loss: 0.4389 | Acc: 85.208% (6711/7876)
(216.3839433901012, 0.8520822752666328)
test:
 164/164 [================================================================================>]  Step: 29ms | Tot: 4s758ms | Loss: 0.4792 | Acc: 84.604% (2220/2624)

===> epoch: 12/20
train:
 493/493 [================================================================================>]  Step: 44ms | Tot: 35s40ms | Loss: 0.4912 | Acc: 83.926% (6610/7876)
(242.14875281602144, 0.8392585068562722)
test:
 164/164 [================================================================================>]  Step: 34ms | Tot: 4s764ms | Loss: 0.4346 | Acc: 85.252% (2237/2624)

===> epoch: 13/20
train:
 493/493 [================================================================================>]  Step: 42ms | Tot: 34s975ms | Loss: 0.4570 | Acc: 84.650% (6667/7876)
(225.3025297690183, 0.8464956830878618)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s717ms | Loss: 0.4532 | Acc: 83.727% (2197/2624)

===> epoch: 14/20
train:
 493/493 [================================================================================>]  Step: 43ms | Tot: 34s993ms | Loss: 0.4563 | Acc: 85.018% (6696/7876)
(224.97076456435025, 0.8501777552056882)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s749ms | Loss: 0.4434 | Acc: 84.909% (2228/2624)

===> epoch: 15/20
train:
 493/493 [================================================================================>]  Step: 41ms | Tot: 34s895ms | Loss: 0.4400 | Acc: 85.310% (6719/7876)
(216.92554211709648, 0.8530980192991366)
test:
 164/164 [================================================================================>]  Step: 28ms | Tot: 4s751ms | Loss: 0.4592 | Acc: 84.566% (2219/2624)

===> epoch: 16/20
train:
 493/493 [================================================================================>]  Step: 42ms | Tot: 34s927ms | Loss: 0.4408 | Acc: 85.310% (6719/7876)
(217.28990308893844, 0.8530980192991366)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s881ms | Loss: 0.4586 | Acc: 84.832% (2226/2624)

===> epoch: 17/20
train:
 493/493 [================================================================================>]  Step: 41ms | Tot: 35s97ms | Loss: 0.4119 | Acc: 86.135% (6784/7876)
(203.07185420766473, 0.8613509395632301)
test:
 164/164 [================================================================================>]  Step: 33ms | Tot: 4s778ms | Loss: 0.4309 | Acc: 85.747% (2250/2624)

===> epoch: 18/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 34s952ms | Loss: 0.4516 | Acc: 86.148% (6785/7876)
(222.65499307215214, 0.861477907567293)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s748ms | Loss: 0.4762 | Acc: 83.384% (2188/2624)

===> epoch: 19/20
train:
 493/493 [================================================================================>]  Step: 42ms | Tot: 34s969ms | Loss: 0.4247 | Acc: 85.830% (6760/7876)
(209.35248641483486, 0.8583037074657186)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s723ms | Loss: 0.4716 | Acc: 85.061% (2232/2624)

===> epoch: 20/20
train:
 493/493 [================================================================================>]  Step: 42ms | Tot: 35s46ms | Loss: 0.4194 | Acc: 86.097% (6781/7876)
(206.74218725040555, 0.8609700355510411)
test:
 164/164 [================================================================================>]  Step: 28ms | Tot: 4s736ms | Loss: 0.4634 | Acc: 84.985% (2230/2624)
===> BEST ACC. PERFORMANCE: 85.747%
Checkpoint saved to ./checkpoints/vgg13-19584684.pth

PS D:\alex_ee4146> python -u ./train.py
Total # images:7876, labels:7876
Total # images:2624, labels:2624
D:\anaconda3\lib\site-packages\torch\optim\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()
` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
D:\anaconda3\lib\site-packages\torch\optim\lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. Du
ring the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch
/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

===> epoch: 1/20
train:
 493/493 [================================================================================>]  Step: 490ms | Tot: 1m4s | Loss: 0.7743 | Acc: 74.848% (5895/7876)2))
(381.71122720092535, 0.7484763839512443)
test:
 164/164 [================================================================================>]  Step: 34ms | Tot: 6s574ms | Loss: 0.8069 | Acc: 72.752% (1909/2624)

===> epoch: 2/20
train:
 493/493 [================================================================================>]  Step: 134ms | Tot: 1m4s | Loss: 0.4797 | Acc: 83.316% (6562/7876)0))
(236.46962393820286, 0.8331640426612493)
test:
 164/164 [================================================================================>]  Step: 36ms | Tot: 6s470ms | Loss: 0.6382 | Acc: 81.364% (2135/2624)

===> epoch: 3/20
train:
 493/493 [================================================================================>]  Step: 106ms | Tot: 1m5s | Loss: 0.4289 | Acc: 85.094% (6702/7876)8))
(211.44409562647343, 0.850939563230066)
test:
 164/164 [================================================================================>]  Step: 41ms | Tot: 6s505ms | Loss: 0.4409 | Acc: 85.404% (2241/2624)

===> epoch: 4/20
train:
 493/493 [================================================================================>]  Step: 100ms | Tot: 1m5s | Loss: 0.3773 | Acc: 86.872% (6842/7876)8))
(186.0029602572322, 0.8687150837988827)
test:
 164/164 [================================================================================>]  Step: 39ms | Tot: 6s717ms | Loss: 0.4003 | Acc: 87.119% (2286/2624)

===> epoch: 5/20
train:
 493/493 [================================================================================>]  Step: 99ms | Tot: 1m5s | Loss: 0.3498 | Acc: 87.989% (6930/7876)76))
(172.42710802331567, 0.8798882681564246)
test:
 164/164 [================================================================================>]  Step: 35ms | Tot: 6s463ms | Loss: 0.5969 | Acc: 81.479% (2138/2624)

===> epoch: 6/20
train:
 493/493 [================================================================================>]  Step: 121ms | Tot: 1m5s | Loss: 0.3369 | Acc: 88.484% (6969/7876)6))
(166.10358396545053, 0.8848400203148806)
test:
 164/164 [================================================================================>]  Step: 48ms | Tot: 6s532ms | Loss: 0.4848 | Acc: 83.803% (2199/2624)

===> epoch: 7/20
train:
 493/493 [================================================================================>]  Step: 123ms | Tot: 1m4s | Loss: 0.3298 | Acc: 88.598% (6978/7876)0))
(162.58888716623187, 0.8859827323514474)
test:
 164/164 [================================================================================>]  Step: 33ms | Tot: 6s506ms | Loss: 0.4176 | Acc: 85.861% (2253/2624)

===> epoch: 8/20
train:
 493/493 [================================================================================>]  Step: 124ms | Tot: 1m4s | Loss: 0.2997 | Acc: 89.563% (7054/7876)4))
(147.7724760696292, 0.8956323006602336)
test:
 164/164 [================================================================================>]  Step: 39ms | Tot: 6s491ms | Loss: 0.2955 | Acc: 89.977% (2361/2624)

===> epoch: 9/20
train:
 493/493 [================================================================================>]  Step: 112ms | Tot: 1m4s | Loss: 0.2730 | Acc: 90.477% (7126/7876)4))
(134.5868573402986, 0.904773996952768)
test:
 164/164 [================================================================================>]  Step: 38ms | Tot: 6s577ms | Loss: 0.3651 | Acc: 87.805% (2304/2624)

===> epoch: 10/20
train:
 493/493 [================================================================================>]  Step: 127ms | Tot: 1m4s | Loss: 0.2645 | Acc: 90.998% (7167/7876)8))
(130.38664332963526, 0.9099796851193499)
test:
 164/164 [================================================================================>]  Step: 35ms | Tot: 6s462ms | Loss: 0.4369 | Acc: 85.366% (2240/2624)

===> epoch: 11/20
train:
 493/493 [================================================================================>]  Step: 111ms | Tot: 1m4s | Loss: 0.2567 | Acc: 90.731% (7146/7876)2))
(126.57134027872235, 0.9073133570340274)
test:
 164/164 [================================================================================>]  Step: 44ms | Tot: 6s481ms | Loss: 0.5393 | Acc: 83.346% (2187/2624)

===> epoch: 12/20
train:
 493/493 [================================================================================>]  Step: 99ms | Tot: 1m4s | Loss: 0.2394 | Acc: 91.887% (7237/7876)40))
(118.02843899838626, 0.9188674454037582)
test:
 164/164 [================================================================================>]  Step: 34ms | Tot: 6s397ms | Loss: 0.3267 | Acc: 89.634% (2352/2624)

===> epoch: 13/20
train:
 493/493 [================================================================================>]  Step: 115ms | Tot: 1m4s | Loss: 0.2127 | Acc: 92.598% (7293/7876)0))
(104.85386220365763, 0.9259776536312849)
test:
 164/164 [================================================================================>]  Step: 45ms | Tot: 6s425ms | Loss: 0.3835 | Acc: 87.767% (2303/2624)

===> epoch: 14/20
train:
 493/493 [================================================================================>]  Step: 100ms | Tot: 1m4s | Loss: 0.1999 | Acc: 92.763% (7306/7876)8))
(98.57069478370249, 0.9276282376841036)
test:
 164/164 [================================================================================>]  Step: 43ms | Tot: 6s547ms | Loss: 0.3780 | Acc: 87.157% (2287/2624)

===> epoch: 15/20
train:
 493/493 [================================================================================>]  Step: 123ms | Tot: 1m4s | Loss: 0.1871 | Acc: 93.588% (7371/7876)6))
(92.25888852309436, 0.935881157948197)
test:
 164/164 [================================================================================>]  Step: 34ms | Tot: 6s565ms | Loss: 0.3601 | Acc: 89.024% (2336/2624)

===> epoch: 16/20
train:
 493/493 [================================================================================>]  Step: 134ms | Tot: 1m5s | Loss: 0.2283 | Acc: 92.382% (7276/7876)2))
(112.56471246760339, 0.9238191975622143)
test:
 164/164 [================================================================================>]  Step: 35ms | Tot: 6s484ms | Loss: 0.4810 | Acc: 84.261% (2211/2624)

===> epoch: 17/20
train:
 493/493 [================================================================================>]  Step: 108ms | Tot: 1m4s | Loss: 0.1920 | Acc: 93.461% (7361/7876)6))
(94.64213308133185, 0.9346114779075673)
test:
 164/164 [================================================================================>]  Step: 34ms | Tot: 6s425ms | Loss: 0.3095 | Acc: 90.396% (2372/2624)

===> epoch: 18/20
train:
 493/493 [================================================================================>]  Step: 101ms | Tot: 1m4s | Loss: 0.1519 | Acc: 94.413% (7436/7876)2))
(74.8937561060302, 0.9441340782122905)
test:
 164/164 [================================================================================>]  Step: 39ms | Tot: 6s458ms | Loss: 0.3310 | Acc: 90.625% (2378/2624)

===> epoch: 19/20
train:
 493/493 [================================================================================>]  Step: 112ms | Tot: 1m4s | Loss: 0.1349 | Acc: 95.442% (7517/7876)2))
(66.51782898476813, 0.9544184865413916)
test:
 164/164 [================================================================================>]  Step: 46ms | Tot: 6s488ms | Loss: 0.4373 | Acc: 87.767% (2303/2624)

===> epoch: 20/20
train:
 493/493 [================================================================================>]  Step: 126ms | Tot: 1m4s | Loss: 0.1459 | Acc: 94.451% (7439/7876)0))
(71.95075992273632, 0.9445149822244794)
test:
 164/164 [================================================================================>]  Step: 36ms | Tot: 6s368ms | Loss: 0.3819 | Acc: 89.177% (2340/2624)
===> BEST ACC. PERFORMANCE: 90.625%
Checkpoint saved to ./checkpoints/resnet101-5d3b4d8f.pth
PS D:\alex_ee4146> python -u ./train.py
Total # images:7876, labels:7876
Total # images:2624, labels:2624
D:\anaconda3\lib\site-packages\torch\optim\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()
` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
D:\anaconda3\lib\site-packages\torch\optim\lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. Du
ring the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch
/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

===> epoch: 1/20
train:
 493/493 [================================================================================>]  Step: 770ms | Tot: 1m31s | Loss: 0.7473 | Acc: 76.054% (5990/7876)))
(368.39908127486706, 0.760538344337227)
test:
 164/164 [================================================================================>]  Step: 52ms | Tot: 8s38ms | Loss: 26.7450 | Acc: 52.973% (1390/2624)

===> epoch: 2/20
train:
 493/493 [================================================================================>]  Step: 180ms | Tot: 1m29s | Loss: 0.4773 | Acc: 84.027% (6618/7876)))
(235.28767588734627, 0.840274250888776)
test:
 164/164 [================================================================================>]  Step: 43ms | Tot: 7s915ms | Loss: 0.3623 | Acc: 87.309% (2291/2624)

===> epoch: 3/20
train:
 493/493 [================================================================================>]  Step: 197ms | Tot: 1m29s | Loss: 0.4043 | Acc: 86.021% (6775/7876)))
(199.3076451085508, 0.8602082275266633)
test:
 164/164 [================================================================================>]  Step: 42ms | Tot: 7s951ms | Loss: 0.3789 | Acc: 87.309% (2291/2624)

===> epoch: 4/20
train:
 493/493 [================================================================================>]  Step: 153ms | Tot: 1m29s | Loss: 0.3763 | Acc: 86.783% (6835/7876)))
(185.5229166597128, 0.8678263077704419)
test:
 164/164 [================================================================================>]  Step: 53ms | Tot: 7s969ms | Loss: 0.4252 | Acc: 86.928% (2281/2624)

===> epoch: 5/20
train:
 493/493 [================================================================================>]  Step: 200ms | Tot: 1m29s | Loss: 0.3420 | Acc: 88.154% (6943/7876)))
(168.61443395912647, 0.8815388522092432)
test:
 164/164 [================================================================================>]  Step: 49ms | Tot: 8s25ms | Loss: 0.6064 | Acc: 82.355% (2161/2624)

===> epoch: 6/20
train:
 493/493 [================================================================================>]  Step: 154ms | Tot: 1m29s | Loss: 0.3290 | Acc: 88.738% (6989/7876)))
(162.17649115249515, 0.8873793803961402)
test:
 164/164 [================================================================================>]  Step: 55ms | Tot: 7s974ms | Loss: 0.3895 | Acc: 86.662% (2274/2624)

===> epoch: 7/20
train:
 493/493 [================================================================================>]  Step: 152ms | Tot: 1m29s | Loss: 0.3141 | Acc: 88.916% (7003/7876)))
(154.86742147058249, 0.8891569324530219)
test:
 164/164 [================================================================================>]  Step: 46ms | Tot: 8s80ms | Loss: 0.4162 | Acc: 85.480% (2243/2624)

===> epoch: 8/20
train:
 493/493 [================================================================================>]  Step: 170ms | Tot: 1m29s | Loss: 0.3341 | Acc: 88.281% (6953/7876)))
(164.73522536084056, 0.882808532249873)
test:
 164/164 [================================================================================>]  Step: 52ms | Tot: 8s32ms | Loss: 0.4009 | Acc: 86.966% (2282/2624)

===> epoch: 9/20
train:
 493/493 [================================================================================>]  Step: 151ms | Tot: 1m30s | Loss: 0.2884 | Acc: 89.665% (7062/7876)))
(142.20518290251493, 0.8966480446927374)
test:
 164/164 [================================================================================>]  Step: 41ms | Tot: 7s952ms | Loss: 0.3920 | Acc: 87.652% (2300/2624)

===> epoch: 10/20
train:
 493/493 [================================================================================>]  Step: 159ms | Tot: 1m28s | Loss: 0.2809 | Acc: 90.287% (7111/7876)))
(138.50227150600404, 0.9028694768918233)
test:
 164/164 [================================================================================>]  Step: 53ms | Tot: 7s959ms | Loss: 1.2227 | Acc: 83.689% (2196/2624)

===> epoch: 11/20
train:
 493/493 [================================================================================>]  Step: 198ms | Tot: 1m29s | Loss: 0.2609 | Acc: 90.947% (7163/7876)))
(128.6195356696844, 0.909471813103098)
test:
 164/164 [================================================================================>]  Step: 42ms | Tot: 7s933ms | Loss: 0.3621 | Acc: 87.881% (2306/2624)

===> epoch: 12/20
train:
 493/493 [================================================================================>]  Step: 142ms | Tot: 1m29s | Loss: 0.2479 | Acc: 91.163% (7180/7876)))
(122.20633364841342, 0.9116302691721686)
test:
 164/164 [================================================================================>]  Step: 55ms | Tot: 8s19ms | Loss: 0.4212 | Acc: 88.415% (2320/2624)

===> epoch: 13/20
train:
 493/493 [================================================================================>]  Step: 158ms | Tot: 1m29s | Loss: 0.2313 | Acc: 91.811% (7231/7876)))
(114.03369097039104, 0.9181056373793804)
test:
 164/164 [================================================================================>]  Step: 54ms | Tot: 7s835ms | Loss: 0.5061 | Acc: 84.794% (2225/2624)

===> epoch: 14/20
train:
 493/493 [================================================================================>]  Step: 164ms | Tot: 1m29s | Loss: 0.2408 | Acc: 91.315% (7192/7876)))
(118.71191032323986, 0.9131538852209243)
test:
 164/164 [================================================================================>]  Step: 56ms | Tot: 7s965ms | Loss: 0.3897 | Acc: 88.300% (2317/2624)

===> epoch: 15/20
train:
 493/493 [================================================================================>]  Step: 144ms | Tot: 1m30s | Loss: 0.2068 | Acc: 92.864% (7314/7876)))
(101.94099128409289, 0.9286439817166074)
test:
 164/164 [================================================================================>]  Step: 48ms | Tot: 7s888ms | Loss: 0.3809 | Acc: 88.186% (2314/2624)

===> epoch: 16/20
train:
 493/493 [================================================================================>]  Step: 143ms | Tot: 1m29s | Loss: 0.1927 | Acc: 93.220% (7342/7876)))
(94.99757657106966, 0.9321990858303707)
test:
 164/164 [================================================================================>]  Step: 49ms | Tot: 7s937ms | Loss: 0.3015 | Acc: 90.434% (2373/2624)

===> epoch: 17/20
train:
 493/493 [================================================================================>]  Step: 168ms | Tot: 1m30s | Loss: 0.1791 | Acc: 93.436% (7359/7876)))
(88.31724673742428, 0.9343575418994413)
test:
 164/164 [================================================================================>]  Step: 41ms | Tot: 8s7ms | Loss: 0.3669 | Acc: 88.072% (2311/2624))

===> epoch: 18/20
train:
 493/493 [================================================================================>]  Step: 152ms | Tot: 1m30s | Loss: 0.1639 | Acc: 94.172% (7417/7876)))
(80.82694134046324, 0.941721686135094)
test:
 164/164 [================================================================================>]  Step: 60ms | Tot: 7s861ms | Loss: 0.3578 | Acc: 89.177% (2340/2624)

===> epoch: 19/20
train:
 493/493 [================================================================================>]  Step: 202ms | Tot: 1m30s | Loss: 0.1533 | Acc: 94.401% (7435/7876)))
(75.59667722007725, 0.9440071102082275)
test:
 164/164 [================================================================================>]  Step: 44ms | Tot: 7s944ms | Loss: 0.4037 | Acc: 88.224% (2315/2624)

===> epoch: 20/20
train:
 493/493 [================================================================================>]  Step: 159ms | Tot: 1m29s | Loss: 0.1305 | Acc: 95.505% (7522/7876)))
(64.35254314518534, 0.9550533265617065)
test:
 164/164 [================================================================================>]  Step: 46ms | Tot: 8s168ms | Loss: 0.4530 | Acc: 86.395% (2267/2624)
===> BEST ACC. PERFORMANCE: 90.434%
Checkpoint saved to ./checkpoints/resnet152-b121ed2d.pth

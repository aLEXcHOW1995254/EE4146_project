D:\anaconda3\envs\pytorch\python.exe D:/alex_ee4146/train.py
Total # images:7876, labels:7876
Total # images:2624, labels:2624

===> epoch: 1/20
train:
D:\anaconda3\envs\pytorch\lib\site-packages\torch\optim\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
D:\anaconda3\envs\pytorch\lib\site-packages\torch\optim\lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
 493/493 [================================================================================>]  Step: 913ms | Tot: 40s236ms | Loss: 1.9325 | Acc: 50.114% (3947/7876)
(952.7100211679935, 0.5011427120365668)
test:
 164/164 [================================================================================>]  Step: 26ms | Tot: 4s818ms | Loss: 0.8081 | Acc: 69.855% (1833/2624)

===> epoch: 2/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s256ms | Loss: 0.9466 | Acc: 65.617% (5168/7876)
(466.6688651740551, 0.6561706449974607)
test:
 164/164 [================================================================================>]  Step: 26ms | Tot: 4s795ms | Loss: 1.1078 | Acc: 54.306% (1425/2624)

===> epoch: 3/20
train:
 493/493 [================================================================================>]  Step: 49ms | Tot: 39s291ms | Loss: 0.8620 | Acc: 69.655% (5486/7876)
(424.9846779629588, 0.696546470289487)
test:
 164/164 [================================================================================>]  Step: 32ms | Tot: 4s801ms | Loss: 0.8823 | Acc: 65.892% (1729/2624)

===> epoch: 4/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s418ms | Loss: 0.7582 | Acc: 73.718% (5806/7876)
(373.78547279536724, 0.7371762315896394)
test:
 164/164 [================================================================================>]  Step: 29ms | Tot: 4s825ms | Loss: 0.6647 | Acc: 75.953% (1993/2624)

===> epoch: 5/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s368ms | Loss: 0.7306 | Acc: 75.254% (5927/7876)
(360.1701189801097, 0.7525393600812595)
test:
 164/164 [================================================================================>]  Step: 31ms | Tot: 4s832ms | Loss: 0.6404 | Acc: 78.582% (2062/2624)

===> epoch: 6/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s375ms | Loss: 0.6529 | Acc: 78.111% (6152/7876)
(321.9025979936123, 0.7811071609954292)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s936ms | Loss: 1.1989 | Acc: 52.134% (1368/2624)

===> epoch: 7/20
train:
 493/493 [================================================================================>]  Step: 49ms | Tot: 39s666ms | Loss: 0.6867 | Acc: 75.432% (5941/7876)
(338.5625692233443, 0.7543169121381412)
test:
 164/164 [================================================================================>]  Step: 34ms | Tot: 5s47ms | Loss: 0.6724 | Acc: 77.630% (2037/2624)

===> epoch: 8/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s692ms | Loss: 0.6224 | Acc: 78.619% (6192/7876)
(306.86701665073633, 0.7861858811579482)
test:
 164/164 [================================================================================>]  Step: 34ms | Tot: 5s89ms | Loss: 0.5408 | Acc: 80.602% (2115/2624)

===> epoch: 9/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s531ms | Loss: 0.5766 | Acc: 79.990% (6300/7876)
(284.25269140303135, 0.7998984255967496)
test:
 164/164 [================================================================================>]  Step: 32ms | Tot: 4s896ms | Loss: 0.5097 | Acc: 82.127% (2155/2624)

===> epoch: 10/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s448ms | Loss: 0.5791 | Acc: 81.171% (6393/7876)
(285.4811122119427, 0.8117064499746064)
test:
 164/164 [================================================================================>]  Step: 34ms | Tot: 4s823ms | Loss: 0.5604 | Acc: 81.402% (2136/2624)

===> epoch: 11/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s406ms | Loss: 0.6007 | Acc: 79.634% (6272/7876)
(296.1302432268858, 0.7963433214829863)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s869ms | Loss: 0.6433 | Acc: 77.744% (2040/2624)

===> epoch: 12/20
train:
 493/493 [================================================================================>]  Step: 46ms | Tot: 39s406ms | Loss: 0.6501 | Acc: 77.273% (6086/7876)
(320.5039548650384, 0.7727272727272727)
test:
 164/164 [================================================================================>]  Step: 31ms | Tot: 4s890ms | Loss: 0.6118 | Acc: 77.934% (2045/2624)

===> epoch: 13/20
train:
 493/493 [================================================================================>]  Step: 47ms | Tot: 39s535ms | Loss: 0.9150 | Acc: 66.988% (5276/7876)
(451.07641188800335, 0.669883189436262)
test:
 164/164 [================================================================================>]  Step: 31ms | Tot: 4s868ms | Loss: 0.8323 | Acc: 69.665% (1828/2624)

===> epoch: 14/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s434ms | Loss: 0.8049 | Acc: 70.366% (5542/7876)
(396.7935739457607, 0.7036566785170137)
test:
 164/164 [================================================================================>]  Step: 26ms | Tot: 4s919ms | Loss: 0.6388 | Acc: 79.154% (2077/2624)

===> epoch: 15/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s533ms | Loss: 0.6188 | Acc: 78.466% (6180/7876)
(305.045812740922, 0.7846622651091925)
test:
 164/164 [================================================================================>]  Step: 28ms | Tot: 4s904ms | Loss: 0.5469 | Acc: 80.373% (2109/2624)

===> epoch: 16/20
train:
 493/493 [================================================================================>]  Step: 47ms | Tot: 39s285ms | Loss: 0.5558 | Acc: 81.056% (6384/7876)
(273.99243407696486, 0.8105637379380396)
test:
 164/164 [================================================================================>]  Step: 28ms | Tot: 4s864ms | Loss: 0.5324 | Acc: 81.174% (2130/2624)

===> epoch: 17/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s564ms | Loss: 0.5628 | Acc: 80.625% (6350/7876)
(277.4831576272845, 0.8062468257998985)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s926ms | Loss: 0.5871 | Acc: 78.049% (2048/2624)

===> epoch: 18/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s560ms | Loss: 0.5780 | Acc: 80.625% (6350/7876)
(284.9747800678015, 0.8062468257998985)
test:
 164/164 [================================================================================>]  Step: 30ms | Tot: 4s802ms | Loss: 0.5008 | Acc: 82.393% (2162/2624)

===> epoch: 19/20
train:
 493/493 [================================================================================>]  Step: 44ms | Tot: 39s555ms | Loss: 0.5286 | Acc: 82.212% (6475/7876)
(260.59077670797706, 0.8221178263077704)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s892ms | Loss: 0.5141 | Acc: 82.355% (2161/2624)

===> epoch: 20/20
train:
 493/493 [================================================================================>]  Step: 45ms | Tot: 39s500ms | Loss: 0.5199 | Acc: 82.770% (6519/7876)
(256.3074913993478, 0.8277044184865414)
test:
 164/164 [================================================================================>]  Step: 27ms | Tot: 4s903ms | Loss: 0.5738 | Acc: 81.517% (2139/2624)
===> BEST ACC. PERFORMANCE: 82.393%
Checkpoint saved to ./checkpoints/vgg19-dcbb9e9d.pth

Process finished with exit code 0
PS D:\alex_ee4146> python -u ./train.py --resume 'checkpoints/densenet161-8d451a50.pth' 
Total # images:7876, labels:7876
Total # images:2624, labels:2624
number of features in block1 384
number of features in block2 768
number of features in block3 2112
number of features in block4 2208
D:\anaconda3\lib\site-packages\torch\optim\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()
` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
D:\anaconda3\lib\site-packages\torch\optim\lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. Du
ring the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch
/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

===> epoch: 1/20
train:
 493/493 [================================================================================>]  Step: 2s565ms | Tot: 1m38s | Loss: 0.7223 | Acc: 75.241% (5926/7876)
(356.09679286926985, 0.7524123920771966)
test:
 164/164 [================================================================================>]  Step: 51ms | Tot: 8s289ms | Loss: 0.5697 | Acc: 81.021% (2126/2624)

===> epoch: 2/20
train:
 493/493 [================================================================================>]  Step: 178ms | Tot: 1m35s | Loss: 0.4548 | Acc: 84.243% (6635/7876)))
(224.22891968861222, 0.8424327069578467)
test:
 164/164 [================================================================================>]  Step: 48ms | Tot: 8s127ms | Loss: 0.4889 | Acc: 81.402% (2136/2624)

===> epoch: 3/20
train:
 493/493 [================================================================================>]  Step: 151ms | Tot: 1m34s | Loss: 0.3857 | Acc: 86.745% (6832/7876)))
(190.15935181826353, 0.867445403758253)
test:
 164/164 [================================================================================>]  Step: 41ms | Tot: 7s969ms | Loss: 0.3253 | Acc: 88.910% (2333/2624)

===> epoch: 4/20
train:
 493/493 [================================================================================>]  Step: 213ms | Tot: 1m35s | Loss: 0.3424 | Acc: 88.167% (6944/7876)))
(168.7880098745227, 0.8816658202133062)
test:
 164/164 [================================================================================>]  Step: 54ms | Tot: 7s997ms | Loss: 0.3436 | Acc: 88.758% (2329/2624)

===> epoch: 5/20
train:
 493/493 [================================================================================>]  Step: 157ms | Tot: 1m36s | Loss: 0.3114 | Acc: 89.132% (7020/7876)))
(153.50085187517107, 0.8913153885220925)
test:
 164/164 [================================================================================>]  Step: 46ms | Tot: 8s139ms | Loss: 0.4828 | Acc: 83.765% (2198/2624)

===> epoch: 6/20
train:
 493/493 [================================================================================>]  Step: 171ms | Tot: 1m35s | Loss: 0.2986 | Acc: 90.008% (7089/7876)))
(147.1875315895304, 0.9000761808024378)
test:
 164/164 [================================================================================>]  Step: 42ms | Tot: 8s169ms | Loss: 0.3981 | Acc: 86.662% (2274/2624)

===> epoch: 7/20
train:
 493/493 [================================================================================>]  Step: 160ms | Tot: 1m35s | Loss: 0.2685 | Acc: 90.909% (7160/7876)))
(132.35470669250935, 0.9090909090909091)
test:
 164/164 [================================================================================>]  Step: 52ms | Tot: 8s22ms | Loss: 0.3253 | Acc: 89.367% (2345/2624)

===> epoch: 8/20
train:
 493/493 [================================================================================>]  Step: 155ms | Tot: 1m35s | Loss: 0.2748 | Acc: 90.401% (7120/7876)))
(135.48815717268735, 0.9040121889283901)
test:
 164/164 [================================================================================>]  Step: 57ms | Tot: 8s33ms | Loss: 0.2869 | Acc: 90.320% (2370/2624)

===> epoch: 9/20
train:
 493/493 [================================================================================>]  Step: 198ms | Tot: 1m34s | Loss: 0.2593 | Acc: 91.061% (7172/7876)))
(127.82284828275442, 0.9106145251396648)
test:
 164/164 [================================================================================>]  Step: 44ms | Tot: 8s26ms | Loss: 0.2664 | Acc: 91.425% (2399/2624)

===> epoch: 10/20
train:
 493/493 [================================================================================>]  Step: 183ms | Tot: 1m35s | Loss: 0.2448 | Acc: 91.607% (7215/7876)))
(120.67286710813642, 0.9160741493143728)
test:
 164/164 [================================================================================>]  Step: 51ms | Tot: 8s91ms | Loss: 0.2486 | Acc: 91.616% (2404/2624)

===> epoch: 11/20
train:
 493/493 [================================================================================>]  Step: 180ms | Tot: 1m35s | Loss: 0.2091 | Acc: 92.725% (7303/7876)))
(103.09406263404526, 0.9272473336719147)
test:
 164/164 [================================================================================>]  Step: 61ms | Tot: 8s69ms | Loss: 0.3049 | Acc: 89.825% (2357/2624)

===> epoch: 12/20
train:
 493/493 [================================================================================>]  Step: 188ms | Tot: 1m35s | Loss: 0.2047 | Acc: 92.547% (7289/7876)))
(100.91755229840055, 0.925469781615033)
test:
 164/164 [================================================================================>]  Step: 47ms | Tot: 8s133ms | Loss: 0.2730 | Acc: 91.159% (2392/2624)

===> epoch: 13/20
train:
 493/493 [================================================================================>]  Step: 193ms | Tot: 1m35s | Loss: 0.1883 | Acc: 93.423% (7358/7876)))
(92.82267428492196, 0.9342305738953783)
test:
 164/164 [================================================================================>]  Step: 46ms | Tot: 8s50ms | Loss: 0.2898 | Acc: 90.473% (2374/2624)

===> epoch: 14/20
train:
 493/493 [================================================================================>]  Step: 174ms | Tot: 1m34s | Loss: 0.1792 | Acc: 93.512% (7365/7876)))
(88.32339993072674, 0.9351193499238192)
test:
 164/164 [================================================================================>]  Step: 55ms | Tot: 7s996ms | Loss: 0.3919 | Acc: 87.462% (2295/2624)

===> epoch: 15/20
train:
 493/493 [================================================================================>]  Step: 166ms | Tot: 1m35s | Loss: 0.1887 | Acc: 93.296% (7348/7876)))
(93.00890884036198, 0.9329608938547486)
test:
 164/164 [================================================================================>]  Step: 48ms | Tot: 7s924ms | Loss: 0.2555 | Acc: 91.387% (2398/2624)

===> epoch: 16/20
train:
 493/493 [================================================================================>]  Step: 169ms | Tot: 1m35s | Loss: 0.1430 | Acc: 94.718% (7460/7876)))
(70.5138122306671, 0.9471813103098019)
test:
 164/164 [================================================================================>]  Step: 53ms | Tot: 8s68ms | Loss: 0.3225 | Acc: 89.748% (2355/2624)

===> epoch: 17/20
train:
 493/493 [================================================================================>]  Step: 169ms | Tot: 1m35s | Loss: 0.1575 | Acc: 94.261% (7424/7876)))
(77.65306473197415, 0.9426104621635348)
test:
 164/164 [================================================================================>]  Step: 50ms | Tot: 8s69ms | Loss: 0.2984 | Acc: 90.434% (2373/2624)

===> epoch: 18/20
train:
 493/493 [================================================================================>]  Step: 179ms | Tot: 1m34s | Loss: 0.1500 | Acc: 94.921% (7476/7876)))
(73.96321702562273, 0.9492127983748095)
test:
 164/164 [================================================================================>]  Step: 56ms | Tot: 7s983ms | Loss: 0.3320 | Acc: 89.977% (2361/2624)

===> epoch: 19/20
train:
 493/493 [================================================================================>]  Step: 176ms | Tot: 1m35s | Loss: 0.1467 | Acc: 95.112% (7491/7876)))
(72.33169947122224, 0.9511173184357542)
test:
 164/164 [================================================================================>]  Step: 49ms | Tot: 7s972ms | Loss: 0.2888 | Acc: 91.502% (2401/2624)

===> epoch: 20/20
train:
 493/493 [================================================================================>]  Step: 173ms | Tot: 1m36s | Loss: 0.1576 | Acc: 94.807% (7467/7876)))
(77.71130318078212, 0.9480700863382427)
test:
 164/164 [================================================================================>]  Step: 43ms | Tot: 7s990ms | Loss: 0.3212 | Acc: 89.672% (2353/2624)
===> BEST ACC. PERFORMANCE: 91.616%
Checkpoint saved to ./checkpoints/densenet161-8d451a50.pth

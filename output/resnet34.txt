D:\anaconda3\envs\pytorch\python.exe D:/alex_ee4146/train.py
Total # images:7876, labels:7876
Total # images:2624, labels:2624

===> epoch: 1/20
train:
D:\anaconda3\envs\pytorch\lib\site-packages\torch\optim\lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
D:\anaconda3\envs\pytorch\lib\site-packages\torch\optim\lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
 493/493 [================================================================================>]  Step: 313ms | Tot: 27s682ms | Loss: 0.7567 | Acc: 77.489% (6103/7876)
(373.0749310106039, 0.7748857287963433)
test:
 164/164 [================================================================================>]  Step: 23ms | Tot: 4s53ms | Loss: 0.4057 | Acc: 86.128% (2260/2624)

===> epoch: 2/20
train:
 493/493 [================================================================================>]  Step: 42ms | Tot: 27s401ms | Loss: 0.5961 | Acc: 80.396% (6332/7876)
(293.8866376876831, 0.8039614017267649)
test:
 164/164 [================================================================================>]  Step: 25ms | Tot: 3s957ms | Loss: 0.6012 | Acc: 82.127% (2155/2624)

===> epoch: 3/20
train:
 493/493 [================================================================================>]  Step: 53ms | Tot: 27s451ms | Loss: 0.4064 | Acc: 85.767% (6755/7876)
(200.3689044751227, 0.8576688674454037)
test:
 164/164 [================================================================================>]  Step: 20ms | Tot: 4s19ms | Loss: 0.3810 | Acc: 86.966% (2282/2624)

===> epoch: 4/20
train:
 493/493 [================================================================================>]  Step: 35ms | Tot: 27s119ms | Loss: 0.3525 | Acc: 88.090% (6938/7876)
(173.79735017940402, 0.8809040121889284)
test:
 164/164 [================================================================================>]  Step: 20ms | Tot: 4s30ms | Loss: 0.4158 | Acc: 84.489% (2217/2624)

===> epoch: 5/20
train:
 493/493 [================================================================================>]  Step: 46ms | Tot: 27s350ms | Loss: 0.3163 | Acc: 88.725% (6988/7876)
(155.92252095602453, 0.8872524123920772)
test:
 164/164 [================================================================================>]  Step: 20ms | Tot: 4s23ms | Loss: 0.3513 | Acc: 87.271% (2290/2624)

===> epoch: 6/20
train:
 493/493 [================================================================================>]  Step: 34ms | Tot: 27s450ms | Loss: 0.3008 | Acc: 89.652% (7061/7876)
(148.27324104495347, 0.8965210766886744)
test:
 164/164 [================================================================================>]  Step: 20ms | Tot: 4s59ms | Loss: 0.5581 | Acc: 80.221% (2105/2624)

===> epoch: 7/20
train:
 493/493 [================================================================================>]  Step: 51ms | Tot: 27s521ms | Loss: 0.2750 | Acc: 90.350% (7116/7876)
(135.5707974480465, 0.9035043169121382)
test:
 164/164 [================================================================================>]  Step: 22ms | Tot: 4s21ms | Loss: 0.5061 | Acc: 82.508% (2165/2624)

===> epoch: 8/20
train:
 493/493 [================================================================================>]  Step: 39ms | Tot: 27s352ms | Loss: 0.2675 | Acc: 90.376% (7118/7876)
(131.88372206036001, 0.9037582529202641)
test:
 164/164 [================================================================================>]  Step: 20ms | Tot: 4s37ms | Loss: 0.3391 | Acc: 88.643% (2326/2624)

===> epoch: 9/20
train:
 493/493 [================================================================================>]  Step: 56ms | Tot: 27s409ms | Loss: 0.2310 | Acc: 91.480% (7205/7876)
(113.89582931809127, 0.914804469273743)
test:
 164/164 [================================================================================>]  Step: 25ms | Tot: 3s956ms | Loss: 0.4347 | Acc: 85.976% (2256/2624)

===> epoch: 10/20
train:
 493/493 [================================================================================>]  Step: 41ms | Tot: 27s553ms | Loss: 0.2084 | Acc: 92.877% (7315/7876)
(102.72113341931254, 0.9287709497206704)
test:
 164/164 [================================================================================>]  Step: 19ms | Tot: 3s996ms | Loss: 0.2812 | Acc: 90.320% (2370/2624)

===> epoch: 11/20
train:
 493/493 [================================================================================>]  Step: 41ms | Tot: 27s290ms | Loss: 0.1991 | Acc: 92.737% (7304/7876)
(98.160671972204, 0.9273743016759777)
test:
 164/164 [================================================================================>]  Step: 20ms | Tot: 3s953ms | Loss: 0.3692 | Acc: 87.119% (2286/2624)

===> epoch: 12/20
train:
 493/493 [================================================================================>]  Step: 53ms | Tot: 26s992ms | Loss: 0.1771 | Acc: 93.880% (7394/7876)
(87.28861958254129, 0.9388014220416455)
test:
 164/164 [================================================================================>]  Step: 19ms | Tot: 3s999ms | Loss: 0.4116 | Acc: 86.928% (2281/2624)

===> epoch: 13/20
train:
 493/493 [================================================================================>]  Step: 49ms | Tot: 27s283ms | Loss: 0.1801 | Acc: 93.728% (7382/7876)
(88.79744231887162, 0.9372778059928898)
test:
 164/164 [================================================================================>]  Step: 30ms | Tot: 3s890ms | Loss: 0.3551 | Acc: 89.520% (2349/2624)

===> epoch: 14/20
train:
 493/493 [================================================================================>]  Step: 42ms | Tot: 27s415ms | Loss: 0.1379 | Acc: 95.226% (7500/7876)
(68.00010960991494, 0.952260030472321)
test:
 164/164 [================================================================================>]  Step: 30ms | Tot: 3s997ms | Loss: 0.3628 | Acc: 89.139% (2339/2624)

===> epoch: 15/20
train:
 493/493 [================================================================================>]  Step: 35ms | Tot: 27s51ms | Loss: 0.1356 | Acc: 95.340% (7509/7876)
(66.86926156783011, 0.9534027425088878)
test:
 164/164 [================================================================================>]  Step: 23ms | Tot: 4s57ms | Loss: 0.3262 | Acc: 90.396% (2372/2624)

===> epoch: 16/20
train:
 493/493 [================================================================================>]  Step: 32ms | Tot: 27s278ms | Loss: 0.1199 | Acc: 95.797% (7545/7876)
(59.095875405706465, 0.9579735906551549)
test:
 164/164 [================================================================================>]  Step: 22ms | Tot: 3s983ms | Loss: 0.4353 | Acc: 87.157% (2287/2624)

===> epoch: 17/20
train:
 493/493 [================================================================================>]  Step: 40ms | Tot: 27s323ms | Loss: 0.1048 | Acc: 96.166% (7574/7876)
(51.68226757796947, 0.9616556627729812)
test:
 164/164 [================================================================================>]  Step: 20ms | Tot: 3s939ms | Loss: 0.3639 | Acc: 90.282% (2369/2624)

===> epoch: 18/20
train:
 493/493 [================================================================================>]  Step: 40ms | Tot: 27s294ms | Loss: 0.1016 | Acc: 96.331% (7587/7876)
(50.09354282054119, 0.9633062468257999)
test:
 164/164 [================================================================================>]  Step: 30ms | Tot: 3s893ms | Loss: 0.3397 | Acc: 90.587% (2377/2624)

===> epoch: 19/20
train:
 493/493 [================================================================================>]  Step: 32ms | Tot: 27s209ms | Loss: 0.0839 | Acc: 97.042% (7643/7876)
(41.360399750235956, 0.9704164550533265)
test:
 164/164 [================================================================================>]  Step: 29ms | Tot: 3s995ms | Loss: 0.4100 | Acc: 88.529% (2323/2624)

===> epoch: 20/20
train:
 493/493 [================================================================================>]  Step: 39ms | Tot: 27s432ms | Loss: 0.0994 | Acc: 96.546% (7604/7876)
(49.002155584224965, 0.9654647028948705)
test:
 164/164 [================================================================================>]  Step: 23ms | Tot: 3s960ms | Loss: 0.3738 | Acc: 88.910% (2333/2624)
===> BEST ACC. PERFORMANCE: 90.587%
Checkpoint saved to ./checkpoints/resnet34-333f7ec4.pth

Process finished with exit code 0